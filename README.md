# Credit Risk Probability Model for Alternative Data

## Project Overview
This project aims to develop an end-to-end credit risk probability model for Bati Bank, leveraging transaction data from an e-commerce platform. The model will assess customer creditworthiness to facilitate a "buy-now-pay-later" service, transforming behavioral data into a predictive risk signal by analyzing customer Recency, Frequency, and Monetary (RFM) patterns.

## Dataset Schema
The dataset contains transaction-level information with the following fields:
- `TransactionId`: Unique transaction identifier
- `BatchId`: ID for a batch of transactions
- `AccountId`: Unique customer ID
- `SubscriptionId`: Customerâ€™s subscription ID
- `CustomerId`: Linked to Account
- `CurrencyCode`: Currency used
- `CountryCode`: Numeric country code
- `ProviderId`: Source of purchased item
- `ProductId`: Purchased item
- `ProductCategory`: Category of item
- `ChannelId`: Platform used (web, Android, iOS, etc.)
- `Amount`: Transaction value (positive = debit, negative = credit)
- `Value`: Absolute amount (absolute amount of the transaction [cite: 3])
- `TransactionStartTime`: When transaction began
- `PricingStrategy`: Pricing category used
- `FraudResult`: Fraud status of transaction (1 = fraud, 0 = no fraud)
---
## Credit Scoring Business Understanding

#### 1. Basel IIâ€™s Emphasis on Risk Measurement: Need for Interpretability and Documentation ğŸ§©
Basel II introduced risk-sensitive regulatory capital under **Pillar 1**, requiring financial institutions to hold capital proportional to the **Probability of Default (PD)**, **Loss Given Default (LGD)**, and **Exposure at Default (EAD)**[cite: 4]. This regulatory environment demands:

- **Transparent model logic** so regulators and internal validators can trace how each feature influences PD.
- **Thorough documentation** of data sources, transformations, assumptions, and performance metrics to satisfy auditing standards and the three lines of defense[cite: 5].

An interpretable, well-documented model ensures compliance, better risk governance, and trust in capital adequacy.

#### 2. Necessity of Proxy Variables for "Default" Labels & Associated Business Risks âš ï¸

- **Why proxy variables?** True default events are rare and key datasets seldom include explicit â€œdefaultâ€ flags. To train models, we must use **proxy events** (e.g., 60+ days past due, charge-offs) as labels[cite: 6].

- **Business risks of proxy-based predictions:** 1. **Label noise** â€“ proxies may not consistently indicate eventual default, leading to inaccurate PD estimates. 
  2. **Regulatory judgment** â€“ if proxy misaligns with regulatory definitions, model outcomes could be challenged in audits. 
  3. **Decision bias** â€“ incorrectly flagging or clearing borrowers based on imperfect signals could result in credit losses or missed business opportunities.


#### 3. Trade-Offs: Simple vs. Complex Models in Regulated Financial Context ğŸ§ 

| Aspect              | Simple, Interpretable Models (e.g., Logistic Regression + WoE) | Complex, High-Performance Models (e.g., Gradient Boosting) |
|---------------------|---------------------------------------------------------------|------------------------------------------------------------|
| **Interpretability** | âœ… Clear feature effects, easy rationale for credit decisions | âŒ Often opaque; needs auxiliary explainability tools       |
| **Regulatory Approval** | âœ… Easily documented, validated, and approved               | âš ï¸ Harder to validate; may face resistance                 |
| **Performance** | Moderate predictive power                                     | [cite_start]âœ… Higher discrimination, especially with non-linear relationships [cite: 7] |
| **Implementation Cost** | Low complexity, fast deployment                               | Higher computational cost and integration overhead         |
| **Governance** | Easier to monitor post-launch                                 | Requires advanced governance for drift, fairness, feature updating |

**In a regulated setting**, the preference often leans toward a simpler, interpretable model unless a complex modelâ€™s performance gain is substantial and justifiable in terms of:

- enhanced risk-adjusted capital efficiency,
- investment into documentation (e.g., SHAP values, surrogate models),
- and ongoing validation frameworks.

---

#### ğŸ§¾ Summary

To comply with Basel II:

- **Interpretability and strong documentation** are non-negotiable for demonstrating accurate risk measurement and governance.
- **Proxy variables** are essential for modeling-but come with label risks that must be managed.
- **Model choice** is a balancing act: simplicity ensures regulatory alignment; complexity can deliver superior performanceâ€”but demands robust validation, documentation, and justification.

## Project Structure
This repository follows a standardized project structure for developing, deploying, and automating a credit risk probability model.

```
credit-risk-model/                      # Root project folder
    â”œâ”€â”€ .github/                            # GitHub CI/CD workflows
    â”‚   â””â”€â”€ workflows/
    â”‚       â””â”€â”€ ci.yml                      # GitHub Actions config
    â”‚
    â”œâ”€â”€ data/                               # Data storage (.gitignored)
    â”‚   â”œâ”€â”€ raw/                            # Original raw data files
    â”‚   â””â”€â”€ processed/                      # Processed/feature-engineered data
    â”‚
    â”œâ”€â”€ notebooks/                          # Exploratory analysis
    â”‚   â”œâ”€â”€ 01_data_exploration.ipynb       # Initial EDA and data profiling
    â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb    # Feature analysis and experiments
    â”‚   â”œâ”€â”€ 03_model_experimentation.ipynb  # Model training and evaluation
    â”‚   â”œâ”€â”€ 04_results_analysis.ipynb       # Final metrics and visualizations
    â”‚   â””â”€â”€ README.md                       # Notebook documentation
    â”‚
    â”œâ”€â”€ src/                                # Production code
    â”‚   â”œâ”€â”€ __init__.py                     # Python package marker
    â”‚   â”œâ”€â”€ data_processing.py              # Feature engineering pipeline
    â”‚   â”œâ”€â”€ train.py                        # Model training script
    â”‚   â”œâ”€â”€ predict.py                      # Inference script
    â”‚   â”‚
    â”‚   â””â”€â”€ api/                            # Deployment components
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â”œâ”€â”€ main.py                     # FastAPI application
    â”‚       â””â”€â”€ pydantic_models.py          # API request/response schemas
    â”‚
    â”œâ”€â”€ tests/                              # Unit tests
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ test_data_processing.py         # Feature engineering tests
    â”‚   â””â”€â”€ test_models.py                  # Model validation tests
    â”‚
    â”œâ”€â”€ Dockerfile                          # Container configuration
    â”œâ”€â”€ docker-compose.yml                  # Multi-container setup
    â”œâ”€â”€ requirements.txt                    # Python dependencies
    â”œâ”€â”€ .gitignore                          # Ignored files/directories
    â””â”€â”€ README.md                           # Project documentation
```